import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# --- 1. Read input data from previous node ---
if 'dm_inputdf' not in locals():
    raise NameError("dm_inputdf not defined. Check preceding node configuration.")
data = dm_inputdf.copy()
print(f"âœ… Loaded data with shape: {data.shape}")

# Define the list of system/ID columns that should NOT be part of the feature matrix (X)
excluded_cols = ['CustomerID', '_PartInd_']

# --- 2. Identify numeric columns for PCA ---
all_numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
numeric_cols_for_pca = [col for col in all_numeric_cols if col not in excluded_cols]

if not numeric_cols_for_pca:
    raise ValueError("Error: No numeric columns found for PCA after excluding IDs.")

print(f"\nðŸ“Š Performing PCA on {len(numeric_cols_for_pca)} features...")

# --- 3. PCA transformation ---
X = data[numeric_cols_for_pca]
pca = PCA(n_components=0.90, random_state=42)
X_pca = pca.fit_transform(X)

# Determine the number of components created
n_components = X_pca.shape[1]
pc_names = [f"PC_{i+1}" for i in range(n_components)]

# Create a DataFrame for the PCA scores
X_pca_df = pd.DataFrame(X_pca, columns=pc_names, index=data.index)

print(f"âœ… PCA fitted: reduced {len(numeric_cols_for_pca)} features to {n_components} components.")
print(f"ðŸ“ˆ Total variance explained: {pca.explained_variance_ratio_.sum():.2%}")

# --- 4. PCA INTERPRETATION: Loadings Analysis ---
print("\n" + "="*80)
print("PCA COMPONENT INTERPRETATION")
print("="*80)

# Get the PCA loadings (component coefficients)
pca_components = pca.components_

# Create a DataFrame showing how each original feature contributes to each PC
loadings_df = pd.DataFrame(
    pca_components.T,
    columns=pc_names,
    index=numeric_cols_for_pca
)

# Analyze and print top contributing features for each component
print("Top contributing features for each Principal Component:")
component_interpretations = {}

for i, pc in enumerate(pc_names):
    print(f"\nðŸ” {pc} (Variance: {pca.explained_variance_ratio_[i]:.2%}):")
    
    # Get top 5 features with highest absolute loading for this PC
    top_features = loadings_df[pc].abs().sort_values(ascending=False).head(5)
    component_features = []
    
    for feature, loading in top_features.items():
        direction = "positively" if loadings_df.loc[feature, pc] > 0 else "negatively"
        print(f"   - {feature}: {loading:.4f} ({direction} correlated)")
        component_features.append((feature, loading, direction))
    
    component_interpretations[pc] = component_features

# --- 5. PCA VISUALIZATION: Scree Plot ---
plt.figure(figsize=(10, 6))
variance_ratio = pca.explained_variance_ratio_
components = range(1, len(variance_ratio) + 1)

plt.subplot(1, 2, 1)
plt.bar(components, variance_ratio, alpha=0.7, color='skyblue')
plt.plot(components, np.cumsum(variance_ratio), 'ro-', linewidth=2, markersize=6)
plt.axhline(y=0.90, color='r', linestyle='--', alpha=0.7, label='90% Variance')
plt.xlabel('Principal Component')
plt.ylabel('Variance Explained')
plt.title('PCA Scree Plot')
plt.legend()
plt.grid(True, alpha=0.3)

# --- 6. Combine with original features ---
data_output = pd.concat([data, X_pca_df], axis=1)

# --- 7. Store interpretation data for clustering phase ---
dm_pca_interpretation = {
    'loadings_df': loadings_df,
    'variance_explained': pca.explained_variance_ratio_,
    'component_interpretations': component_interpretations,
    'original_features': numeric_cols_for_pca,
    'pca_model': pca
}

# --- 8. Metadata hand-off for new PCA components ---
dm_meta_add = pd.DataFrame({
    "Name": pc_names,
    "Role": ["INPUT"] * n_components,
    "Level": ["INTERVAL"] * n_components
})

# --- 9. Define outputs for downstream nodes ---
dm_outputdf = data_output.copy()
dm_scoreddf = data_output.copy()
dm_add_meta = dm_meta_add.copy()

print("\n" + "="*80)
print("âœ… PCA FEATURE REDUCTION COMPLETE")
print("="*80)
print(f"â€¢ Reduced from {len(numeric_cols_for_pca)} to {n_components} components")
print(f"â€¢ Variance retained: {pca.explained_variance_ratio_.sum():.2%}")
print(f"â€¢ Component interpretations stored for clustering analysis")
print(f"â€¢ New PC variables passed forward with INPUT/INTERVAL roles")
